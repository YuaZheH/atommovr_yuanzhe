from atommover.algorithms.source.inside_out_utils import *

def inside_out_algorithm(rbcs_arrays: AtomArray, round_lim: int = 50):
    """
    Inside out rearrangement algorithm proposed by the Bernien lab at the University of Chicago.
    """
    arrays = copy.deepcopy(rbcs_arrays)
    move_list = []
    move_list_layer = []
    
    if check_atom_enough(rbcs_arrays) == False:
        return rbcs_arrays, [], False
    
    layer_num = 1 # The index control which layer we are rearranging
    iteration = 0

    # Start deal with the n-th layer rearrangement
    while rearrangement_complete(arrays) == False and iteration < round_lim:
        arrays_save = copy.deepcopy(arrays)
        if layer_complete(layer_num, arrays, is_site_correct(arrays)):
            move_list.extend(move_list_layer)
            move_list_layer = []
            #If the rearrangement is not completed, we move on next outer layer
            if not rearrangement_complete(arrays):
                layer_num += 1 
        else:
            if np.array_equal(arrays.matrix, arrays_save.matrix) and iteration > 0:
                arrays, moves = inside_out_layer_push(arrays, layer_num, get_stuck_flag = True)
            else:
                arrays, moves = inside_out_layer_push(arrays, layer_num, get_stuck_flag = False)

            if moves == None:
                return rbcs_arrays, None, False
            move_list_layer.extend(moves)
            iteration += 1

            # Check if the rearrangement disturbs inner (previous) layer
            for check_layer in range(layer_num, 0, -1): 
                if not layer_complete(check_layer, arrays, is_site_correct(arrays)):
                    layer_num = check_layer
                    
    if rearrangement_complete(arrays):
        move_list.extend(move_list_layer)

    return arrays, clean_empty_moves(rbcs_arrays, move_list), rearrangement_complete(arrays)

def check_atom_enough(arrays: AtomArray) -> bool:
    """
    Check if the initial arrays have enough atoms to rearrange.
    """
    Rb_num = np.sum(arrays.matrix[:,:,0])
    Cs_num = np.sum(arrays.matrix[:,:,1])
    Rb_target_num = np.sum(arrays.target_Rb)
    Cs_target_num = np.sum(arrays.target_Cs)
    
    if Rb_num >= Rb_target_num and Cs_num >= Cs_target_num:
        return True
    else:
        return False
    
def rearrangement_complete(arrays: AtomArray) -> bool:
    """
    Check if the rearrangement complete for both Rb and Cs.
    """
    Rb_complete = np.array_equal(np.multiply(arrays.matrix[:,:,0], arrays.target_Rb), arrays.target_Rb)
    Cs_complete = np.array_equal(np.multiply(arrays.matrix[:,:,1], arrays.target_Cs), arrays.target_Cs)
    return Rb_complete and Cs_complete

def layer_complete(layer_factor: int, arrays: AtomArray, is_site_correct: Callable[[int, int], bool]) -> bool:
    """
    Check if the layer of an atom array is complete for both Rb and Cs.
    A layer is 'complete' if, along the perimeter of this layer, 
    the array matches the target for both Rb and Cs.
    """
    # Extract Rb & Cs layers plus their target arrays
    Rb_arrays = arrays.matrix[:, :, 0]
    Rb_target = arrays.target_Rb
    Cs_arrays = arrays.matrix[:, :, 1]
    Cs_target = arrays.target_Cs

    # Define the boundary for this layer
    n = Rb_arrays.shape[0]
    top, left, bottom, right = def_boundary(layer_factor - 1, n)

    # Boundary check
    if top < 0 or left < 0 or bottom >= n or right >= n:
        return False

    # If layer_factor == 0, it's just the center cell
    if top == bottom and left == right:
        return (Rb_arrays[top, left] == Rb_target[top, left] and Cs_arrays[top, left] == Cs_target[top, left])

    # Check perimeter cells; if any mismatch, layer isn't complete
    for (r, c) in perimeter_coords(top, left, bottom, right):
        if not is_site_correct(r, c):
            return False

    return True

def inside_out_layer_push(rbcs_arrays: AtomArray, layer_factor: int, get_stuck_flag: bool):
    arrays = copy.deepcopy(rbcs_arrays)
    move_list = []

    # Push out all misplace atoms
    arrays, push_out_moves = push_out_misplaced_atoms(arrays, layer_factor)
    move_list.extend(push_out_moves)

    if check_atom_enough(arrays) == False:
        return arrays, None

    # Check if the process get stuck
    while True:
        N_independent_path_move_in, categ_2_pair_in = generate_path_inside_out_new(arrays, layer_factor, 'in')
        
        if len(N_independent_path_move_in) == 0:
            break
        if get_stuck_flag:
            for move in N_independent_path_move_in[0]:
                arrays.move_atoms([move])
                move_list.append([move])
        else:
            arrays, categ_1_moves_in = transform_paths_into_moves(arrays, N_independent_path_move_in, max_rounds = 1)
            move_list.extend(categ_1_moves_in)

    if len(categ_2_pair_in) > 0:
        arrays, all_categ_2_moves = handle_categ_2_paths(arrays, categ_2_pair_in, layer_factor)
        move_list.extend(all_categ_2_moves)

    return arrays, move_list

def rearrangement_complete(arrays: AtomArray) -> bool:
    """
    It should call the layer_complete function (every layer complete->rearrangement complete)
    """
    Rb_complete = np.array_equal(np.multiply(arrays.matrix[:,:,0], arrays.target_Rb), arrays.target_Rb)
    Cs_complete = np.array_equal(np.multiply(arrays.matrix[:,:,1], arrays.target_Cs), arrays.target_Cs)
    return Rb_complete and Cs_complete

def push_out_misplaced_atoms(arrays: AtomArray, layer_factor: int):
    # 1. Get the coordinate of misplaced atoms
    Rb_source_layer = collect_coords(arrays, layer_factor, 'layer', is_rb_source(arrays))
    Cs_source_layer = collect_coords(arrays, layer_factor, 'layer', is_cs_source(arrays))
    Rb_target_layer = collect_coords(arrays, layer_factor, 'layer', is_rb_target(arrays))
    Cs_target_layer = collect_coords(arrays, layer_factor, 'layer', is_cs_target(arrays))

    # 2. Push out all misplaced atoms
    arrays, push_moves = crude_push_atoms(arrays, layer_factor, Rb_source_layer, Cs_source_layer)

    return arrays, push_moves

def crude_push_atoms(
    arrays: AtomArray,
    layer_factor: int,
    Rb_source_layer: list[tuple[int,int]],
    Cs_source_layer: list[tuple[int,int]]
) -> tuple[AtomArray, list[list[Move]]]:
    push_moves_dict = {(1, 0): [], (0, 1): [], (-1, 0): [], (0, -1): []}
    non_parallel_push_moves_dict = {(1, 0): [], (0, 1): [], (-1, 0): [], (0, -1): []}
    push_moves = []
    op_matrix = copy.deepcopy(arrays.matrix[:, :, 0] + arrays.matrix[:, :, 1])

    misplaced_atoms = Rb_source_layer + Cs_source_layer

    for obs_coord in misplaced_atoms:
        # Find a good site to push
        push_coord, push_dir, distance = find_push_coord_misplaced(arrays, obs_coord, layer_factor)

        if distance == 1: # direct push
            move = Move(obs_coord[0], obs_coord[1], push_coord[0], push_coord[1])
            arrays.move_atoms([move])
            #push_moves.append([move])
            push_moves_dict[(push_dir[0], push_dir[1])].extend([move])
            non_parallel_push_moves_dict[(push_dir[0], push_dir[1])].append([move])
        else: # chain push
            chain_list = chain_push_move(obs_coord, push_coord, push_dir)
            arrays.move_atoms(chain_list)
            #push_moves.append(chain_list)
            push_moves_dict[(push_dir[0], push_dir[1])].extend(chain_list)
            non_parallel_push_moves_dict[(push_dir[0], push_dir[1])].append(chain_list)

    if len(push_moves_dict[(1, 0)]) > 0:
        horiz_AOD_cmds, vert_AOD_cmds, parallel_success_flag = generate_AOD_cmds(op_matrix, push_moves_dict[(1, 0)])
        if parallel_success_flag:
            push_moves.append(push_moves_dict[(1, 0)])
        else:
            for push_line in non_parallel_push_moves_dict[(1, 0)]:
                push_moves.append(push_line)

    if len(push_moves_dict[(0, 1)]) > 0:
        horiz_AOD_cmds, vert_AOD_cmds, parallel_success_flag = generate_AOD_cmds(op_matrix, push_moves_dict[(0, 1)])
        if parallel_success_flag:
            push_moves.append(push_moves_dict[(0, 1)])
        else:
            for push_line in non_parallel_push_moves_dict[(0, 1)]:
                push_moves.append(push_line)

    if len(push_moves_dict[(-1, 0)]) > 0:
        horiz_AOD_cmds, vert_AOD_cmds, parallel_success_flag = generate_AOD_cmds(op_matrix, push_moves_dict[(-1, 0)])
        if parallel_success_flag:
            push_moves.append(push_moves_dict[(-1, 0)])
        else:
            for push_line in non_parallel_push_moves_dict[(-1, 0)]:
                push_moves.append(push_line)

    if len(push_moves_dict[(0, -1)]) > 0:
        horiz_AOD_cmds, vert_AOD_cmds, parallel_success_flag = generate_AOD_cmds(op_matrix, push_moves_dict[(0, -1)])
        if parallel_success_flag:
            push_moves.append(push_moves_dict[(0, -1)])
        else:
            for push_line in non_parallel_push_moves_dict[(0, -1)]:
                push_moves.append(push_line)

    return arrays, push_moves

def find_target_neighbor(source_layer, target_layer):
    dir = [(dr, dc) for dr in [-1, 0, 1] for dc in [-1, 0, 1] if (abs(dr) + abs(dc)) == 1]
    for dr, dc in dir:
        if (source_layer[0] + dr, source_layer[1] + dc) in target_layer:
            return (source_layer[0] + dr, source_layer[1] + dc), (dr, dc)
    return None, None

def find_push_coord_misplaced(arrays: AtomArray, obs_coord: tuple[int,int], layer_factor: int) -> tuple[int,int]:
    """
    1) Identify which directions are outward.
    2) Exclude directions used by the path or that go inward.
    3) For each remaining direction, find the nearest empty site.
    """
    obs_r, obs_c = obs_coord

    # 1) Build candidate directions
    push_dir = find_push_dir(arrays, layer_factor, obs_coord)

    # 2) For each direction, find the nearest empty site. We'll store (found_coord, direction)
    ejection_flag = True
    dr, dc = push_dir[0], push_dir[1]
    site = find_empty_in_direction(arrays, obs_r, obs_c, dr, dc, ejection_flag)

    dist_sq = (((site[0] - obs_r)**2 + (site[1] - obs_c)**2)/(dr**2+dc**2))**0.5

    return site, push_dir, dist_sq

"""
Functions for executing inside_out_layer
"""
def generate_path_inside_out_new(arrays: AtomArray, layer_factor: int, in_or_out: str) -> list:
    """
    For each (start, end), run BFS to find a path. If BFS fails or finds different-species occupant, log to type_2_pair. Return a list of (move_list, category).
    """
    move_list_for_assigns = []
    categ_2_pair = []
    op_arrays = copy.deepcopy(arrays)
    out_assign, in_assign = gen_dual_assign_new(arrays, layer_factor)
    prepared_assignments = out_assign + in_assign

    for start, end in prepared_assignments:
        bfs_res = bfs_find_path_new(op_arrays.matrix, layer_factor, start, end, same_species_ok(op_arrays))
        if bfs_res.end_reached:
            single_path = (process_chain_moves_new(bfs_res))
            move_list_for_assigns = generate_decomposed_move_list(op_arrays, single_path, move_list_for_assigns)
        else:
            categ_2_pair.append((start, end))
    return move_list_for_assigns, categ_2_pair

def transform_paths_into_moves(arrays: AtomArray, all_paths: list[list[Move]], max_rounds: int = 1) -> tuple[AtomArray, list[list[Move]]]:
    """
    Execute up to one move from each path in 'paths' per round, avoiding collisions. Collisions occur if two moves share a 'to' or 'from' coordinate.
    Returns: (arrays, parallel_moves)
    parallel_moves: list of rounds, each round is a list of Move objects that were executed simultaneously.
    """
    parallel_moves = []
    round_count = 0

    """If max_rounds set 1, we could dynamically search newest path every time."""
    while round_count < max_rounds:
        # 1) Gather the candidate move from each path, if available
        move_candidates = []
        for path in all_paths:
            if len(path) > 0: # path is not empty
                move_candidates.append(path[0])  # next move in this path

        # 2) Identify non-conflicting moves among 'candidates'
        moves_in_scan = collect_non_conflicting_moves(move_candidates, arrays)

        # 3) Parallelize moves in this round
        if len(moves_in_scan) > 0:
            matrix = arrays.matrix[:,:,0] + arrays.matrix[:,:,1]
            moves_in_scan = regroup_parallel_moves(matrix, moves_in_scan)
            # 2.1.3 Implement the moves
            parallel_moves.extend(moves_in_scan)
            for moves in moves_in_scan:
                _ = arrays.move_atoms(moves)

        # 4) Remove them from each path
        for move in moves_in_scan:
            for path in all_paths:
                if path and path[0] == move:
                    path.pop(0)  # remove this move from that path
                    break
        round_count += 1

    return arrays, parallel_moves

def handle_categ_2_paths(arrays: AtomArray, categ_2_pairs: list[tuple[int,int]], layer_factor: int) -> tuple[AtomArray, list[list[Move]]]:
    """
    For each 'categ_2' source-target pair (start, end):
      1) Use BFS with same_species_ok to find a path. If no result, use diff_species_ok to find a path.
      2) If BFS finds different-species obstacles, push them aside (crude_push_new).
      3) Convert the final BFS path to a list of moves, apply them if desired.
    """
    all_categ2_moves = []
    op_arrays = copy.deepcopy(arrays)

    for (start, end) in categ_2_pairs:
        # 1) Try to search trivial path again
        bfs_res = bfs_find_path_new(op_arrays.matrix, layer_factor, start, end, same_species_ok(op_arrays))
        if not bfs_res.end_reached:
            bfs_res_allow_diff = bfs_find_path_new(op_arrays.matrix, layer_factor, start, end, diff_species_ok(op_arrays))
            single_path = (process_chain_moves_new(bfs_res_allow_diff))
        else:
            single_path = (process_chain_moves_new(bfs_res))
            op_arrays, all_categ2_moves = categ_2_move_exe(op_arrays, single_path, all_categ2_moves)
            continue
        
        # If BFS found obstacles (diff_obstacle)
        if bfs_res_allow_diff.diff_obstacle:
            # 2) Attempt to push them out
            op_arrays, push_moves = push_out_obstacles(op_arrays, layer_factor, bfs_res_allow_diff.diff_obstacle, single_path)
            # accumulate or log these push moves if you want
            all_categ2_moves.extend(push_moves)

        # 3) Search BFS again to obtain optimal obstacle-free path
        bfs_res = bfs_find_path_new(op_arrays.matrix, layer_factor, start, end, same_species_ok(op_arrays))
        single_path = (process_chain_moves_new(bfs_res))
        op_arrays, all_categ2_moves = categ_2_move_exe(op_arrays, single_path, all_categ2_moves)

    return op_arrays, all_categ2_moves

def find_push_dir(arrays, layer_factor, obs_coord):
    n = arrays.matrix.shape[0]
    top, left, bottom, right = def_boundary(layer_factor-1, n)
    for c in range(left, right + 1):
        if (top, c) == obs_coord:
            return (-1, 0)
    for r in range(top + 1, bottom + 1):
        if (r, right) == obs_coord:
            return (0, 1)
    for c in range(right - 1, left - 1, -1):
        if (bottom, c) == obs_coord:
            return (1, 0)
    for r in range(bottom - 1, top, -1):
        if (r, left) == obs_coord:
            return (0, -1)
